{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "import sys\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import pandas as pd\n",
    "from deslib.util.instance_hardness import kdn_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import BernoulliNB, GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from tabulate import tabulate\n",
    "from tqdm import tqdm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from deslib.dcs import OLA\n",
    "# from deslib.dcs import KNORA_U, KNORA_E\n",
    "from deslib.des import  KNOP, METADES\n",
    "from deslib.static import SingleBest, StackedClassifier\n",
    "from deslib.static import StaticSelection\n",
    "from imblearn.metrics import geometric_mean_score\n",
    "# from pyhard import HardMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES_SET = {\n",
    "    \"feature\": 1,\n",
    "    \"permission\": 2,\n",
    "    \"activity\": 3,\n",
    "    \"service_receiver\": 3,\n",
    "    \"provider\": 3,\n",
    "    \"service\": 3,\n",
    "    \"intent\": 4,\n",
    "    \"api_call\": 5,\n",
    "    \"real_permission\": 6,\n",
    "    \"call\": 7,\n",
    "    \"url\": 8\n",
    "}\n",
    "\n",
    "\n",
    "def count_feature_set(lines):\n",
    "    \"\"\"\n",
    "    Count how many features belong to a specific set\n",
    "    :param lines: features in the text file\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    features_map = {x: 0 for x in range(1, 9)}\n",
    "    for l in lines:\n",
    "        if l != \"\\n\":\n",
    "            set = l.split(\"::\")[0]\n",
    "            features_map[FEATURES_SET[set]] += 1\n",
    "    features = []\n",
    "    for i in range(1, 9):\n",
    "        features.append(features_map[i])\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read(LOAD_DATA=False):\n",
    "    if LOAD_DATA:\n",
    "        print(\"Previous data not loaded. Attempt to read data ...\")\n",
    "        mypath = r\"Drebin\\MetaData\\feature_vectors\\feature_vectors\"\n",
    "        onlyfiles = [f for f in listdir(mypath) if isfile(join(mypath, f))]\n",
    "\n",
    "        print(\"Reading csv file for ground truth ...\")\n",
    "        ground_truth = np.loadtxt(r\"Drebin\\MetaData\\sha256_family.csv\", delimiter=\",\", skiprows=1, dtype=str)\n",
    "        # print ground_truth.shape\n",
    "        # families = np.unique(ground_truth[:, 1])\n",
    "        # print families\n",
    "        # print len(families)\n",
    "\n",
    "        print(\"Reading positive and negative texts ...\")\n",
    "        pos = []\n",
    "        neg = []\n",
    "        for virus in tqdm(onlyfiles):\n",
    "            if virus in ground_truth[:, 0]:\n",
    "                pos.append(virus)\n",
    "            else:\n",
    "                neg.append(virus)\n",
    "\n",
    "        print(\"Extracting features ...\")\n",
    "        x = []\n",
    "        y = []\n",
    "        for text_file in tqdm(pos):\n",
    "            sys.stdin = open(\"%s/%s\" % (mypath, text_file))\n",
    "            features = sys.stdin.readlines()\n",
    "            sample = count_feature_set(features)\n",
    "            x.append(sample)\n",
    "            y.append(1)\n",
    "\n",
    "        for text_file in tqdm(neg):\n",
    "            sys.stdin = open(\"%s/%s\" % (mypath, text_file))\n",
    "            features = sys.stdin.readlines()\n",
    "            sample = count_feature_set(features)\n",
    "            x.append(sample)\n",
    "            y.append(0)\n",
    "\n",
    "        print(\"Data is read successfully:\")\n",
    "        x = np.array(x)\n",
    "        y = np.array(y)\n",
    "        print(x.shape, y.shape)\n",
    "\n",
    "        print(\"Saving data under data_numpy directory ...\")\n",
    "        np.save(r\"x_all.npy\", x)\n",
    "        np.save(r\"y_all.npy\", y)\n",
    "\n",
    "        return x, y\n",
    "    else:\n",
    "        print(\"Loading previous data ...\")\n",
    "        x_ = np.load(r\"x_all.npy\")\n",
    "        y_ = np.load(r\"y_all.npy\")\n",
    "        print(x_.shape, y_.shape)\n",
    "        # print x == x_, y == y_\n",
    "        return x_, y_\n",
    "\n",
    "\n",
    "def map_family_to_category(families):\n",
    "    out = {}\n",
    "    count = 1\n",
    "    for family in families:\n",
    "        out[family] = count\n",
    "        count += 1\n",
    "    return out\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    #x, y = read(LOAD_DATA=True)\n",
    "    x, y = read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "models = {}\n",
    "\n",
    "# Função para ler os dados\n",
    "x0, y0 = read(LOAD_DATA=False)\n",
    "\n",
    "# Caminho do diretório com os modelos\n",
    "dir_path = r'E:\\DrebinStudy\\Balanced\\Bagging2'\n",
    "\n",
    "# Função para criar o gráfico cumulativo para uma seed específica\n",
    "def plot_cumulative_histogram_single_seed(hardness_table, seed):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    for label in ['label_0', 'label_1']:    \n",
    "        # Hits para a seed especificada\n",
    "        hit_scores = hardness_table[label]['Hit'][seed]\n",
    "        sorted_hits = np.sort(hit_scores)\n",
    "        cumulative_hits = np.arange(1, len(sorted_hits) + 1) / len(sorted_hits)\n",
    "        plt.plot(sorted_hits, cumulative_hits, label=f\"{label} - Hit\")\n",
    "\n",
    "        # Misses para a seed especificada\n",
    "        miss_scores = hardness_table[label]['Miss'][seed]\n",
    "        sorted_misses = np.sort(miss_scores)\n",
    "        cumulative_misses = np.arange(1, len(sorted_misses) + 1) / len(sorted_misses)\n",
    "        plt.plot(sorted_misses, cumulative_misses, label=f\"{label} - Miss\", linestyle='--')\n",
    "\n",
    "    # Configurações do gráfico\n",
    "    plt.title(f'Cumulative Hardness Histogram for {seed}')\n",
    "    plt.xlabel('Hardness Score')\n",
    "    plt.ylabel('Cumulative Probability')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Loop para percorrer todas as subpastas dentro de 'Bagging2'\n",
    "for subfolder_name in os.listdir(dir_path):\n",
    "    subfolder_path = os.path.join(dir_path, subfolder_name)\n",
    "    \n",
    "    # Verifica se é uma subpasta\n",
    "    if os.path.isdir(subfolder_path):\n",
    "        print(f'Processando subpasta: {subfolder_name}')\n",
    "        i = 0\n",
    "        hardness_table = {'label_0': {'Hit': {}, 'Miss': {}}, 'label_1': {'Hit': {}, 'Miss': {}}}\n",
    "\n",
    "        # Loop pelas 30 pastas dentro de cada subpasta (1 a 30)\n",
    "        for model_folder in os.listdir(subfolder_path):\n",
    "            model_folder_path = os.path.join(subfolder_path, model_folder)\n",
    "            \n",
    "            if os.path.isdir(model_folder_path):\n",
    "                # Carregar todos os modelos na pasta atual\n",
    "                models_list = []\n",
    "                for model_file in os.listdir(model_folder_path):\n",
    "                    model_path = os.path.join(model_folder_path, model_file)\n",
    "                    model = joblib.load(model_path)\n",
    "                    models_list.append(model)\n",
    "\n",
    "                # Fazer previsões combinadas para cada modelo\n",
    "                x_train, x_test, y_train, y_test = train_test_split(x0, y0, test_size=0.2, stratify=y0, random_state=i)\n",
    "                y_preds = np.array([model.predict(x_test) for model in models_list])\n",
    "                previsoes = np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=0, arr=y_preds)\n",
    "\n",
    "                # Calcular o hardness score\n",
    "                hardness_score = kdn_score(x_test, y_test, k=7)[0]\n",
    "\n",
    "                # Separar os scores por label\n",
    "                for label in [0, 1]:\n",
    "                    hit_scores = hardness_score[(y_test == previsoes) & (y_test == label)]\n",
    "                    miss_scores = hardness_score[(y_test != previsoes) & (y_test == label)]\n",
    "                    hardness_table[f'label_{label}']['Hit'][f'seed-{str(i)}'] = hit_scores\n",
    "                    hardness_table[f'label_{label}']['Miss'][f'seed-{str(i)}'] = miss_scores\n",
    "\n",
    "                print(f\"Hardness médio para seed-{i}: {np.mean(hardness_score):.4f}\")\n",
    "                i += 1\n",
    "                print(f'Modelos processados na pasta: {model_folder_path}')\n",
    "                \n",
    "                # Gerar gráfico cumulativo para o modelo atual\n",
    "                plot_cumulative_histogram_single_seed(hardness_table, f'seed-{i-1}')  # Mostrar para o último seed processado\n",
    "\n",
    "        # Salvar a hardness_table por subpasta\n",
    "        models[subfolder_name] = hardness_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Opcional: normalizar os dados\n",
    "scaler = StandardScaler()\n",
    "x_scaled = scaler.fit_transform(x)\n",
    "\n",
    "# Aplicar t-SNE ou UMAP\n",
    "tsne = TSNE(n_components=3, random_state=42)\n",
    "x_embedded = tsne.fit_transform(x_scaled)\n",
    "\n",
    "# Colocar o resultado em um DataFrame para visualização\n",
    "df = pd.DataFrame(x_embedded, columns=['Dim1', 'Dim2', 'Dim3'])\n",
    "df['Label'] = y  # Adicionar rótulos\n",
    "\n",
    "# Criar o gráfico 3D interativo\n",
    "fig = px.scatter_3d(df, x='Dim1', y='Dim2', z='Dim3', color='Label',\n",
    "                    title=\"Visualização do Espaço de Instâncias com t-SNE\",\n",
    "                    labels={\"Dim1\": \"Componente 1\", \"Dim2\": \"Componente 2\", \"Dim3\": \"Componente 3\"})\n",
    "\n",
    "# Exibir o gráfico\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE(sampling_strategy='auto', k_neighbors=5)\n",
    "x, y = smote.fit_resample(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Opcional: normalizar os dados\n",
    "scaler = StandardScaler()\n",
    "x_scaled = scaler.fit_transform(x)\n",
    "\n",
    "# Aplicar t-SNE ou UMAP\n",
    "tsne = TSNE(n_components=3, random_state=42)\n",
    "x_embedded = tsne.fit_transform(x_scaled)\n",
    "\n",
    "# Colocar o resultado em um DataFrame para visualização\n",
    "df = pd.DataFrame(x_embedded, columns=['Dim1', 'Dim2', 'Dim3'])\n",
    "df['Label'] = y  # Adicionar rótulos\n",
    "\n",
    "# Criar o gráfico 3D interativo\n",
    "fig = px.scatter_3d(df, x='Dim1', y='Dim2', z='Dim3', color='Label',\n",
    "                    title=\"Visualização do Espaço de Instâncias com t-SNE\",\n",
    "                    labels={\"Dim1\": \"Componente 1\", \"Dim2\": \"Componente 2\", \"Dim3\": \"Componente 3\"})\n",
    "\n",
    "# Exibir o gráfico\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0, y0 = read(LOAD_DATA=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificando as novas instâncias\n",
    "num_original_samples = len(x0)\n",
    "num_resampled_samples = len(x)\n",
    "\n",
    "# Adicionando a classe 2 às novas instâncias\n",
    "new_labels = np.array([2] * (num_resampled_samples - num_original_samples))\n",
    "\n",
    "# Unindo os rótulos gerados (classe 2) ao dataset balanceado\n",
    "# As classes 0 e 1 continuam com seus rótulos originais\n",
    "y_modified = np.concatenate([y0, new_labels])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Opcional: normalizar os dados\n",
    "scaler = StandardScaler()\n",
    "x_scaled = scaler.fit_transform(x)\n",
    "\n",
    "# Aplicar t-SNE ou UMAP\n",
    "tsne = TSNE(n_components=3, random_state=42)\n",
    "x_embedded = tsne.fit_transform(x_scaled)\n",
    "\n",
    "# Colocar o resultado em um DataFrame para visualização\n",
    "df = pd.DataFrame(x_embedded, columns=['Dim1', 'Dim2', 'Dim3'])\n",
    "df['Label'] = y_modified  # Adicionar rótulos\n",
    "\n",
    "# Criar o gráfico 3D interativo\n",
    "fig = px.scatter_3d(df, x='Dim1', y='Dim2', z='Dim3', color='Label',\n",
    "                    title=\"Visualização do Espaço de Instâncias com t-SNE\",\n",
    "                    labels={\"Dim1\": \"Componente 1\", \"Dim2\": \"Componente 2\", \"Dim3\": \"Componente 3\"})\n",
    "\n",
    "# Exibir o gráfico\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hardness_table = {}\n",
    "x0, y0 = read(LOAD_DATA=False)\n",
    "for i in range(30):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x0, y0, test_size=0.2, stratify=y0, random_state = i)\n",
    "    hardness_score = kdn_score(x_test, y_test, k=7)[0]\n",
    "    hardness_table[f\"seed-{i}\"] = hardness_score\n",
    "    print(f\"Hardness médio para {f'seed-{i}'}: {np.mean(hardness_score):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Número de gráficos que você deseja (5 neste caso)\n",
    "num_plots = 6\n",
    "\n",
    "# Criar subplots (uma figura com múltiplos gráficos)\n",
    "fig, axs = plt.subplots(num_plots, 1, figsize=(8, num_plots * 4))  # 5 gráficos verticais\n",
    "\n",
    "# Definir a quantidade de modelos por gráfico\n",
    "models_per_plot = len(hardness_table) // num_plots\n",
    "\n",
    "# Iterador para controlar qual gráfico está sendo plotado\n",
    "plot_idx = 0\n",
    "\n",
    "# Iterar sobre os modelos\n",
    "for i, model_name in enumerate(hardness_table):\n",
    "    # Obter dados ordenados e calcular cumulativo\n",
    "    sorted_data = np.sort(hardness_table[model_name])\n",
    "    cumulative = np.arange(1, len(sorted_data) + 1) / len(sorted_data)\n",
    "    \n",
    "    # Plotar no gráfico atual\n",
    "    axs[plot_idx].plot(sorted_data, cumulative, label=f'{model_name}')\n",
    "    axs[plot_idx].set_title(f\"Hardness Distribution for Models {plot_idx+1}\")\n",
    "    axs[plot_idx].set_xlabel(\"Hardness\")\n",
    "    axs[plot_idx].set_ylabel(\"Cumulative Percentage\")\n",
    "    axs[plot_idx].set_ylim(0.90, 1.0)\n",
    "    axs[plot_idx].grid(True)\n",
    "    axs[plot_idx].legend()\n",
    "    \n",
    "    # Mudar para o próximo gráfico a cada `models_per_plot` modelos\n",
    "    if (i + 1) % models_per_plot == 0 and plot_idx < num_plots - 1:\n",
    "        plot_idx += 1\n",
    "\n",
    "# Ajustar o layout para evitar sobreposição\n",
    "plt.tight_layout()\n",
    "\n",
    "# Mostrar o gráfico\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hardness_table = {'label_0': [], 'label_1': []}\n",
    "\n",
    "# Ler os dados\n",
    "x0, y0 = read(LOAD_DATA=False)\n",
    "\n",
    "for i in range(30):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x0, y0, test_size=0.2, stratify=y0, random_state=i)\n",
    "    hardness_score = kdn_score(x_test, y_test, k=7)[0]\n",
    "    \n",
    "    # Separar os scores por label\n",
    "    for label in [0, 1]:\n",
    "        label_scores = hardness_score[y_test == label]\n",
    "        hardness_table[f'label_{label}'].extend(label_scores)\n",
    "    \n",
    "    print(f\"Hardness médio para seed-{i}: {np.mean(hardness_score):.4f}\")\n",
    "\n",
    "# Número de gráficos que você deseja\n",
    "num_plots = 2\n",
    "\n",
    "# Criar subplots (uma figura com múltiplos gráficos)\n",
    "fig, axs = plt.subplots(num_plots, 1, figsize=(8, num_plots * 4))\n",
    "\n",
    "# Iterar sobre os labels\n",
    "for idx, label in enumerate([0, 1]):\n",
    "    # Obter dados ordenados e calcular cumulativo\n",
    "    sorted_data = np.sort(hardness_table[f'label_{label}'])\n",
    "    cumulative = np.arange(1, len(sorted_data) + 1) / len(sorted_data)\n",
    "    \n",
    "    # Plotar no gráfico atual\n",
    "    axs[idx].plot(sorted_data, cumulative, label=f'Label {label}')\n",
    "    axs[idx].set_title(f\"Hardness Distribution for Label {label}\")\n",
    "    axs[idx].set_xlabel(\"Hardness\")\n",
    "    axs[idx].set_ylabel(\"Cumulative Percentage\")\n",
    "    axs[idx].set_ylim(0.0, 1.0)\n",
    "    axs[idx].grid(True)\n",
    "    axs[idx].legend()\n",
    "\n",
    "# Ajustar o layout para evitar sobreposição\n",
    "plt.tight_layout()\n",
    "\n",
    "# Mostrar o gráfico\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hardness_table = {'label_0': {}, 'label_1': {}}\n",
    "\n",
    "# Ler os dados\n",
    "x0, y0 = read(LOAD_DATA=False)\n",
    "\n",
    "for i in range(30):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x0, y0, test_size=0.2, stratify=y0, random_state=i)\n",
    "    hardness_score = kdn_score(x_test, y_test, k=7)[0]\n",
    "    \n",
    "    # Separar os scores por label\n",
    "    for label in [0, 1]:\n",
    "        label_scores = hardness_score[y_test == label]\n",
    "        hardness_table[f'label_{label}'][f'seed-{str(i)}'] = label_scores\n",
    "    \n",
    "    print(f\"Hardness médio para seed-{i}: {np.mean(hardness_score):.4f}\")\n",
    "\n",
    "# Número de gráficos que você deseja\n",
    "num_plots = 6\n",
    "\n",
    "# Iterar sobre os modelos\n",
    "for i, model_name in enumerate(hardness_table):\n",
    "    # Obter dados ordenados e calcular cumulativo\n",
    "    sorted_data = np.sort(hardness_table[model_name])\n",
    "    cumulative = np.arange(1, len(sorted_data) + 1) / len(sorted_data)\n",
    "    \n",
    "    # Plotar no gráfico atual\n",
    "    axs[plot_idx].plot(sorted_data, cumulative, label=f'{model_name}')\n",
    "    axs[plot_idx].set_title(f\"Hardness Distribution for Models {plot_idx+1}\")\n",
    "    axs[plot_idx].set_xlabel(\"Hardness\")\n",
    "    axs[plot_idx].set_ylabel(\"Cumulative Percentage\")\n",
    "    axs[plot_idx].set_ylim(0.90, 1.0)\n",
    "    axs[plot_idx].grid(True)\n",
    "    axs[plot_idx].legend()\n",
    "    \n",
    "    # Mudar para o próximo gráfico a cada `models_per_plot` modelos\n",
    "    if (i + 1) % models_per_plot == 0 and plot_idx < num_plots - 1:\n",
    "        plot_idx += 1\n",
    "\n",
    "# Ajustar o layout para evitar sobreposição\n",
    "plt.tight_layout()\n",
    "\n",
    "# Mostrar o gráfico\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_cumulative_hardness_scores(hardness_table):\n",
    "    # Plotar gráficos cumulativos para cada seed e label\n",
    "    for label in hardness_table.keys():\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        \n",
    "        for seed in hardness_table[label].keys():\n",
    "            scores = np.array(hardness_table[label][seed])\n",
    "            # Ordenar scores para criar o gráfico cumulativo\n",
    "            sorted_scores = np.sort(scores)\n",
    "            # Calcular a distribuição cumulativa\n",
    "            cumulative_distribution = np.arange(1, len(sorted_scores) + 1) / len(sorted_scores)\n",
    "            plt.plot(sorted_scores, cumulative_distribution, label=f'Seed {seed}')\n",
    "        \n",
    "        plt.title(f'Cumulative Hardness Scores for Label {label}')\n",
    "        plt.xlabel('Hardness Score')\n",
    "        plt.ylabel('Cumulative Probability')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "    # Plotar gráficos cumulativos agregados para cada label\n",
    "    for label in hardness_table.keys():\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        all_scores = np.concatenate([np.array(scores) for scores in hardness_table[label].values()])\n",
    "        sorted_scores = np.sort(all_scores)\n",
    "        cumulative_distribution = np.arange(1, len(sorted_scores) + 1) / len(sorted_scores)\n",
    "        plt.plot(sorted_scores, cumulative_distribution, label=f'Label {label}')\n",
    "        \n",
    "        plt.title(f'Cumulative Hardness Scores for Label {label}')\n",
    "        plt.xlabel('Hardness Score')\n",
    "        plt.ylabel('Cumulative Probability')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "# Chamada da função\n",
    "plot_cumulative_hardness_scores(hardness_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_cumulative_hardness_scores_for_seed(hardness_table, seed):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Plotar gráficos cumulativos para cada label\n",
    "    for label in hardness_table.keys():\n",
    "        scores = np.array(hardness_table[label][seed])\n",
    "        # Ordenar scores para criar o gráfico cumulativo\n",
    "        sorted_scores = np.sort(scores)\n",
    "        # Calcular a distribuição cumulativa\n",
    "        cumulative_distribution = np.arange(1, len(sorted_scores) + 1) / len(sorted_scores)\n",
    "        plt.plot(sorted_scores, cumulative_distribution, label=f'Label {label}')\n",
    "    \n",
    "    plt.title(f'Cumulative Hardness Scores for Seed {seed}')\n",
    "    plt.xlabel('Hardness Score')\n",
    "    plt.ylabel('Cumulative Probability')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Escolher a seed específica que você deseja plotar\n",
    "seed_to_plot = 'seed-0'\n",
    "\n",
    "# Chamada da função para a seed específica\n",
    "plot_cumulative_hardness_scores_for_seed(hardness_table, seed_to_plot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "models = {}\n",
    "\n",
    "hardness_table = {'label_0': {'Hit':{}, 'Miss':{}}, 'label_1': {'Hit':{}, 'Miss':{}}}\n",
    "\n",
    "# Ler os dados\n",
    "x0, y0 = read(LOAD_DATA=False)\n",
    "\n",
    "# Caminho do diretório com os modelos\n",
    "dir_path = r'E:\\DrebinStudy\\Unbalanced'\n",
    "\n",
    "# Loop para percorrer todas as pastas no diretório\n",
    "for folder_name in os.listdir(dir_path)[:1]:\n",
    "    folder_path = os.path.join(dir_path, folder_name)\n",
    "    \n",
    "    # Verifica se é uma pasta e se não é a pasta 'Metrics'\n",
    "    if os.path.isdir(folder_path) and folder_name != 'Metrics':\n",
    "        print(f'Processando pasta: {folder_name}')\n",
    "        i = 0\n",
    "        hardness_table = {'label_0': {'Hit':{}, 'Miss':{}}, 'label_1': {'Hit':{}, 'Miss':{}}}\n",
    "        # Aqui você pode inserir o código para processar os modelos dentro da pasta\n",
    "        for file_name in os.listdir(folder_path):\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            x_train, x_test, y_train, y_test = train_test_split(x0, y0, test_size=0.2, stratify=y0, random_state=i)\n",
    "            hardness_score = kdn_score(x_test, y_test, k=7)[0]\n",
    "            model = joblib.load(file_path)\n",
    "            y_pred = model.predict(x_test)\n",
    "\n",
    "            # Separar os scores por label\n",
    "            for label in [0, 1]:\n",
    "                hit_scores = hardness_score[(y_test == y_pred) & (y_test == label)]\n",
    "                miss_scores = hardness_score[(y_test != y_pred) & (y_test == label)]\n",
    "                hardness_table[f'label_{label}']['Hit'][f'seed-{str(i)}'] = hit_scores\n",
    "                hardness_table[f'label_{label}']['Miss'][f'seed-{str(i)}'] = miss_scores\n",
    "            \n",
    "            print(f\"Hardness médio para seed-{i}: {np.mean(hardness_score):.4f}\")\n",
    "            i += 1   \n",
    "            # Faz algo com os arquivos de modelo\n",
    "            print(f'Arquivo de modelo encontrado: {file_path}')\n",
    "        models[folder_name] = hardness_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "models = {}\n",
    "\n",
    "# Função para ler os dados\n",
    "x0, y0 = read(LOAD_DATA=False)\n",
    "\n",
    "# Caminho do diretório com os modelos\n",
    "dir_path = r'E:\\DrebinStudy\\Unbalanced'\n",
    "\n",
    "# Função para criar o gráfico cumulativo para uma seed específica\n",
    "def plot_cumulative_histogram_single_seed(hardness_table, seed):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    for label in ['label_0', 'label_1']:\n",
    "        # Hits para a seed especificada\n",
    "        hit_scores = hardness_table[label]['Hit'][seed]\n",
    "        sorted_hits = np.sort(hit_scores)\n",
    "        cumulative_hits = np.arange(1, len(sorted_hits) + 1) / len(sorted_hits)\n",
    "        plt.plot(sorted_hits, cumulative_hits, label=f\"{label} - Hit\")\n",
    "\n",
    "        # Misses para a seed especificada\n",
    "        miss_scores = hardness_table[label]['Miss'][seed]\n",
    "        sorted_misses = np.sort(miss_scores)\n",
    "        cumulative_misses = np.arange(1, len(sorted_misses) + 1) / len(sorted_misses)\n",
    "        plt.plot(sorted_misses, cumulative_misses, label=f\"{label} - Miss\", linestyle='--')\n",
    "\n",
    "    # Configurações do gráfico\n",
    "    plt.title(f'Cumulative Hardness Histogram for {seed}')\n",
    "    plt.xlabel('Hardness Score')\n",
    "    plt.ylabel('Cumulative Probability')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Loop para percorrer todas as pastas no diretório (tirando 'Metrics')\n",
    "for folder_name in os.listdir(dir_path):\n",
    "    folder_path = os.path.join(dir_path, folder_name)\n",
    "    \n",
    "    # Verifica se é uma pasta e se não é a pasta 'Metrics'\n",
    "    if os.path.isdir(folder_path) and folder_name != 'Metrics':\n",
    "        print(f'Processando pasta: {folder_name}')\n",
    "        i = 0\n",
    "        hardness_table = {'label_0': {'Hit':{}, 'Miss':{}}, 'label_1': {'Hit':{}, 'Miss':{}}}\n",
    "\n",
    "        # Processar os modelos dentro da pasta\n",
    "        for file_name in os.listdir(folder_path):\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            x_train, x_test, y_train, y_test = train_test_split(x0, y0, test_size=0.2, stratify=y0, random_state=i)\n",
    "            hardness_score = kdn_score(x_test, y_test, k=7)[0]\n",
    "            model = joblib.load(file_path)\n",
    "            y_pred = model.predict(x_test)\n",
    "\n",
    "            # Separar os scores por label\n",
    "            for label in [0, 1]:\n",
    "                hit_scores = hardness_score[(y_test == y_pred) & (y_test == label)]\n",
    "                miss_scores = hardness_score[(y_test != y_pred) & (y_test == label)]\n",
    "                hardness_table[f'label_{label}']['Hit'][f'seed-{str(i)}'] = hit_scores\n",
    "                hardness_table[f'label_{label}']['Miss'][f'seed-{str(i)}'] = miss_scores\n",
    "\n",
    "            print(f\"Hardness médio para seed-{i}: {np.mean(hardness_score):.4f}\")\n",
    "            i += 1   \n",
    "            print(f'Arquivo de modelo encontrado: {file_path}')\n",
    "            \n",
    "            # Gerar gráfico cumulativo para o modelo atual\n",
    "            plot_cumulative_histogram_single_seed(hardness_table, f'seed-{i-1}')  # Mostrar para o último seed processado\n",
    "        \n",
    "        # Salvar a hardness_table por pasta\n",
    "        models[folder_name] = hardness_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hardness_table = {'label_0': {'Hit':{}, 'Miss':{}}, 'label_1': {'Hit':{}, 'Miss':{}}}\n",
    "\n",
    "# Ler os dados\n",
    "x0, y0 = read(LOAD_DATA=False)\n",
    "\n",
    "for i in range(30):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x0, y0, test_size=0.2, stratify=y0, random_state=i)\n",
    "    hardness_score = kdn_score(x_test, y_test, k=7)[0]\n",
    "    model = joblib.load(f\"E:\\DrebinStudy\\Balanced\\RandomForest\\model_{i+1}.joblib\")\n",
    "    y_pred = model.predict(x_test)\n",
    "\n",
    "    # Separar os scores por label\n",
    "    for label in [0, 1]:\n",
    "        hit_scores = hardness_score[(y_test == y_pred) & (y_test == label)]\n",
    "        miss_scores = hardness_score[(y_test != y_pred) & (y_test == label)]\n",
    "        hardness_table[f'label_{label}']['Hit'][f'seed-{str(i)}'] = hit_scores\n",
    "        hardness_table[f'label_{label}']['Miss'][f'seed-{str(i)}'] = miss_scores\n",
    "    \n",
    "    print(f\"Hardness médio para seed-{i}: {np.mean(hardness_score):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Função para criar o gráfico cumulativo\n",
    "def plot_cumulative_histogram(hardness_table):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    for label in ['label_0', 'label_1']:\n",
    "        # Hits\n",
    "        hit_scores = np.concatenate([hardness_table[label]['Hit'][seed] for seed in hardness_table[label]['Hit']])\n",
    "        sorted_hits = np.sort(hit_scores)\n",
    "        cumulative_hits = np.arange(1, len(sorted_hits) + 1) / len(sorted_hits)\n",
    "        plt.plot(sorted_hits, cumulative_hits, label=f\"{label} - Hit\")\n",
    "\n",
    "        # Misses\n",
    "        miss_scores = np.concatenate([hardness_table[label]['Miss'][seed] for seed in hardness_table[label]['Miss']])\n",
    "        sorted_misses = np.sort(miss_scores)\n",
    "        cumulative_misses = np.arange(1, len(sorted_misses) + 1) / len(sorted_misses)\n",
    "        plt.plot(sorted_misses, cumulative_misses, label=f\"{label} - Miss\", linestyle='--')\n",
    "\n",
    "    # Configurações do gráfico\n",
    "    plt.title('Cumulative Hardness Histogram')\n",
    "    plt.xlabel('Hardness Score')\n",
    "    plt.ylabel('Cumulative Probability')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Exibir o gráfico\n",
    "plot_cumulative_histogram(hardness_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Função para criar o gráfico cumulativo para uma seed específica\n",
    "def plot_cumulative_histogram_single_seed(hardness_table, seed):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    for label in ['label_0', 'label_1']:\n",
    "        # Hits para a seed especificada\n",
    "        hit_scores = hardness_table[label]['Hit'][seed]\n",
    "        sorted_hits = np.sort(hit_scores)\n",
    "        cumulative_hits = np.arange(1, len(sorted_hits) + 1) / len(sorted_hits)\n",
    "        plt.plot(sorted_hits, cumulative_hits, label=f\"{label} - Hit\")\n",
    "\n",
    "        # Misses para a seed especificada\n",
    "        miss_scores = hardness_table[label]['Miss'][seed]\n",
    "        sorted_misses = np.sort(miss_scores)\n",
    "        cumulative_misses = np.arange(1, len(sorted_misses) + 1) / len(sorted_misses)\n",
    "        plt.plot(sorted_misses, cumulative_misses, label=f\"{label} - Miss\", linestyle='--')\n",
    "\n",
    "    # Configurações do gráfico\n",
    "    plt.title(f'Cumulative Hardness Histogram for {seed}')\n",
    "    plt.xlabel('Hardness Score')\n",
    "    plt.ylabel('Cumulative Probability')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Exibir o gráfico para uma seed específica\n",
    "for i in range(30):\n",
    "    plot_cumulative_histogram_single_seed(hardness_table, f'seed-{i}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
