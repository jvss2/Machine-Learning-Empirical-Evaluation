{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\anaconda3\\Lib\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "import sys\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.utils import resample\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import joblib\n",
    "import concurrent.futures\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import BernoulliNB, GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from tabulate import tabulate\n",
    "from tqdm import tqdm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.metrics import geometric_mean_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import matthews_corrcoef, cohen_kappa_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "import sys\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import BernoulliNB, GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from sklearn.utils import resample\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import joblib\n",
    "from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from tabulate import tabulate\n",
    "from tqdm import tqdm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from deslib.dcs import OLA\n",
    "# from deslib.dcs import KNORA_U, KNORA_E\n",
    "from deslib.des import  KNOP, METADES\n",
    "from deslib.static import SingleBest, StackedClassifier\n",
    "from deslib.static import StaticSelection\n",
    "from imblearn.metrics import geometric_mean_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.load(r\"x_all.npy\")\n",
    "y = np.load(r\"y_all.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(103210, 8) (103210,)\n",
      "(25803, 8) (25803,)\n"
     ]
    }
   ],
   "source": [
    "x_all = np.load(r\"x_all.npy\")\n",
    "y_all = np.load(r\"y_all.npy\")\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_all, y_all, test_size=0.2, stratify=y_all, random_state=42)\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "baggings = {\n",
    "    'DecisionTree': DecisionTreeClassifier(criterion='gini'),\n",
    "    'NaiveBayes': GaussianNB(),\n",
    "    'Knn': KNeighborsClassifier(n_neighbors=7),\n",
    "    'MLP': MLPClassifier(hidden_layer_sizes=(100), max_iter=1000)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrou na função `parallel_training`\n",
      "Iniciando o loop externo (modelos) e intermediário (30 iterações)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Models:   0%|          | 0/120 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mNão é possível executar o código, a sessão foi descartada. Tente reiniciar o Kernel."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mNão é possível executar o código, a sessão foi descartada. Tente reiniciar o Kernel. \n",
      "\u001b[1;31mConsulte o <a href='command:jupyter.viewOutput'>log</a> do Jupyter para obter mais detalhes."
     ]
    }
   ],
   "source": [
    "def train_model(model, x_train, y_train, model_dir, j):\n",
    "    print(f\"Entrou na função `train_model` - Iteração {j + 1}\")\n",
    "    \n",
    "    # Gerar uma amostra bootstrap\n",
    "    print(f\"Gerando amostra bootstrap para a iteração {j + 1}\")\n",
    "    x_resampled, y_resampled = resample(x_train, y_train, replace=True, random_state=j)\n",
    "\n",
    "    # Balancear a amostra usando SMOTE\n",
    "    print(f\"Balanceando a amostra com SMOTE para a iteração {j + 1}\")\n",
    "    smote = SMOTE(sampling_strategy='auto', k_neighbors=5, random_state=j)\n",
    "    x_balanced, y_balanced = smote.fit_resample(x_resampled, y_resampled)\n",
    "\n",
    "    # Treinar o modelo na amostra balanceada\n",
    "    print(f\"Treinando o modelo na iteração {j + 1}\")\n",
    "    model.fit(x_balanced, y_balanced)\n",
    "\n",
    "    # Salva o modelo treinado\n",
    "    model_path = os.path.join(model_dir, f'model_{j + 1}.joblib')\n",
    "    print(f\"Salvando o modelo treinado em {model_path}\")\n",
    "    joblib.dump(model, model_path)\n",
    "    \n",
    "    print(f\"Finalizou a função `train_model` - Iteração {j + 1}\")\n",
    "\n",
    "def train_iteration(modelName, model, i, x_train, y_train):\n",
    "    print(f\"\\nEntrou na função `train_iteration` - Modelo: {modelName}, Iteração: {i + 1}\")\n",
    "    \n",
    "    # Criando o diretório\n",
    "    model_dir = os.path.join(\"E:/DrebinStudy/Balanced/Bagging2\", modelName)\n",
    "    model_dir = os.path.join(model_dir, str(i + 1))\n",
    "    print(f\"Criando diretório {model_dir} para a iteração {i + 1}\")\n",
    "    os.makedirs(model_dir, exist_ok=True)  # Criar o diretório se não existir\n",
    "\n",
    "    # Usar ThreadPoolExecutor para paralelizar o loop interno\n",
    "    with ThreadPoolExecutor() as thread_executor:\n",
    "        futures = []\n",
    "        print(f\"Iniciando o loop interno (100 iterações) - Modelo: {modelName}, Iteração: {i + 1}\")\n",
    "        for j in range(100):\n",
    "            futures.append(thread_executor.submit(train_model, model, x_train, y_train, model_dir, j))\n",
    "        \n",
    "        # Aguardar todas as execuções do loop interno\n",
    "        for future in tqdm(futures, desc=f\"Model {modelName} Iteration {i + 1}\", leave=False):\n",
    "            future.result()  # Garante que exceções sejam capturadas\n",
    "\n",
    "    print(f\"Finalizou a função `train_iteration` - Modelo: {modelName}, Iteração: {i + 1}\\n\")\n",
    "\n",
    "# Função principal para paralelizar os loops externo e intermediário\n",
    "def parallel_training(baggings, x_train, y_train):\n",
    "    print(\"Entrou na função `parallel_training`\")\n",
    "    \n",
    "    # Paralelizar o loop intermediário e externo usando ProcessPoolExecutor\n",
    "    with ProcessPoolExecutor() as process_executor:\n",
    "        futures = []\n",
    "        print(f\"Iniciando o loop externo (modelos) e intermediário (30 iterações)\")\n",
    "        for modelName, model in baggings.items():\n",
    "            print(f\"{model}, {modelName}\")\n",
    "            for i in range(30):\n",
    "                # Envia a tarefa do loop intermediário ao executor\n",
    "                futures.append(process_executor.submit(train_iteration, modelName, model, i, x_train, y_train))\n",
    "\n",
    "        # Aguarda todas as tarefas do loop intermediário e externo\n",
    "        for future in tqdm(futures, desc=\"Training Models\"):\n",
    "            future.result()\n",
    "\n",
    "    print(\"Finalizou a função `parallel_training`\")\n",
    "\n",
    "# Exemplo de chamada da função\n",
    "parallel_training(baggings, x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_number(j):\n",
    "    # Criando o diretório\n",
    "    print(j)\n",
    "    model_dir = os.path.join(\"E:/DrebinStudy/Balanced/Bagging2\", 'DecisionTreeClassifier')\n",
    "    model_dir = os.path.join(model_dir, str(j))\n",
    "    print(model_dir)\n",
    "    os.makedirs(model_dir, exist_ok=True)  # Criar o diretório se não existir\n",
    "\n",
    "    model = DecisionTreeClassifier(criterion='gini')\n",
    "    \n",
    "    # Aqui você precisará passar as variáveis x_train e y_train\n",
    "    x_resampled, y_resampled = resample(x_train, y_train, replace=True, random_state=j)\n",
    "\n",
    "    # Balancear a amostra usando SMOTE\n",
    "    smote = SMOTE(sampling_strategy='auto', k_neighbors=5, random_state=j)\n",
    "    x_balanced, y_balanced = smote.fit_resample(x_resampled, y_resampled)\n",
    "\n",
    "    # Treinar o modelo na amostra balanceada\n",
    "    model.fit(x_balanced, y_balanced)\n",
    "    \n",
    "    # Salvar o modelo treinado\n",
    "    model_path = os.path.join(model_dir, f'model_{j}.joblib')\n",
    "    joblib.dump(model, model_path)\n",
    "\n",
    "# Usando ProcessPoolExecutor para evitar problemas com threads\n",
    "if __name__ == \"__main__\":\n",
    "    with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "        executor.map(print_number, range(1, 101))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [00:00<00:18,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetição 100 NaiveBayes - Acurácia: 0.74, Precisão: 0.11, Recall: 0.70, F1-score: 0.19, ROC AUC: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 2/30 [00:01<00:16,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetição 100 NaiveBayes - Acurácia: 0.71, Precisão: 0.11, Recall: 0.77, F1-score: 0.19, ROC AUC: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 3/30 [00:01<00:16,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetição 100 NaiveBayes - Acurácia: 0.73, Precisão: 0.11, Recall: 0.73, F1-score: 0.19, ROC AUC: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 4/30 [00:02<00:15,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetição 100 NaiveBayes - Acurácia: 0.72, Precisão: 0.11, Recall: 0.75, F1-score: 0.19, ROC AUC: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 5/30 [00:02<00:14,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetição 100 NaiveBayes - Acurácia: 0.73, Precisão: 0.11, Recall: 0.74, F1-score: 0.19, ROC AUC: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 6/30 [00:03<00:14,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetição 100 NaiveBayes - Acurácia: 0.72, Precisão: 0.11, Recall: 0.77, F1-score: 0.19, ROC AUC: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 7/30 [00:04<00:13,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetição 100 NaiveBayes - Acurácia: 0.72, Precisão: 0.11, Recall: 0.75, F1-score: 0.19, ROC AUC: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 8/30 [00:04<00:12,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetição 100 NaiveBayes - Acurácia: 0.72, Precisão: 0.11, Recall: 0.75, F1-score: 0.19, ROC AUC: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 9/30 [00:05<00:12,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetição 100 NaiveBayes - Acurácia: 0.74, Precisão: 0.11, Recall: 0.71, F1-score: 0.19, ROC AUC: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 10/30 [00:05<00:11,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetição 100 NaiveBayes - Acurácia: 0.71, Precisão: 0.10, Recall: 0.74, F1-score: 0.18, ROC AUC: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 11/30 [00:06<00:10,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetição 100 NaiveBayes - Acurácia: 0.71, Precisão: 0.11, Recall: 0.76, F1-score: 0.19, ROC AUC: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 12/30 [00:07<00:10,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetição 100 NaiveBayes - Acurácia: 0.73, Precisão: 0.11, Recall: 0.73, F1-score: 0.19, ROC AUC: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 13/30 [00:07<00:09,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetição 100 NaiveBayes - Acurácia: 0.71, Precisão: 0.11, Recall: 0.77, F1-score: 0.19, ROC AUC: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 14/30 [00:08<00:09,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetição 100 NaiveBayes - Acurácia: 0.73, Precisão: 0.11, Recall: 0.77, F1-score: 0.20, ROC AUC: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 15/30 [00:08<00:08,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetição 100 NaiveBayes - Acurácia: 0.73, Precisão: 0.11, Recall: 0.75, F1-score: 0.19, ROC AUC: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 16/30 [00:09<00:08,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetição 100 NaiveBayes - Acurácia: 0.75, Precisão: 0.11, Recall: 0.68, F1-score: 0.19, ROC AUC: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 17/30 [00:09<00:07,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetição 100 NaiveBayes - Acurácia: 0.74, Precisão: 0.11, Recall: 0.73, F1-score: 0.19, ROC AUC: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 18/30 [00:10<00:06,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetição 100 NaiveBayes - Acurácia: 0.74, Precisão: 0.11, Recall: 0.70, F1-score: 0.19, ROC AUC: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 19/30 [00:11<00:06,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetição 100 NaiveBayes - Acurácia: 0.74, Precisão: 0.11, Recall: 0.68, F1-score: 0.19, ROC AUC: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 20/30 [00:11<00:05,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetição 100 NaiveBayes - Acurácia: 0.74, Precisão: 0.11, Recall: 0.74, F1-score: 0.20, ROC AUC: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 21/30 [00:12<00:05,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetição 100 NaiveBayes - Acurácia: 0.73, Precisão: 0.11, Recall: 0.76, F1-score: 0.20, ROC AUC: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 22/30 [00:12<00:04,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetição 100 NaiveBayes - Acurácia: 0.73, Precisão: 0.11, Recall: 0.75, F1-score: 0.19, ROC AUC: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 23/30 [00:13<00:03,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetição 100 NaiveBayes - Acurácia: 0.74, Precisão: 0.11, Recall: 0.75, F1-score: 0.20, ROC AUC: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 24/30 [00:13<00:03,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetição 100 NaiveBayes - Acurácia: 0.72, Precisão: 0.11, Recall: 0.75, F1-score: 0.19, ROC AUC: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 25/30 [00:14<00:02,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetição 100 NaiveBayes - Acurácia: 0.72, Precisão: 0.11, Recall: 0.75, F1-score: 0.19, ROC AUC: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 26/30 [00:15<00:02,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetição 100 NaiveBayes - Acurácia: 0.71, Precisão: 0.10, Recall: 0.73, F1-score: 0.18, ROC AUC: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 27/30 [00:15<00:01,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetição 100 NaiveBayes - Acurácia: 0.75, Precisão: 0.11, Recall: 0.67, F1-score: 0.19, ROC AUC: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 28/30 [00:16<00:01,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetição 100 NaiveBayes - Acurácia: 0.71, Precisão: 0.11, Recall: 0.77, F1-score: 0.19, ROC AUC: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 29/30 [00:16<00:00,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetição 100 NaiveBayes - Acurácia: 0.73, Precisão: 0.11, Recall: 0.76, F1-score: 0.19, ROC AUC: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:17<00:00,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetição 100 NaiveBayes - Acurácia: 0.75, Precisão: 0.11, Recall: 0.69, F1-score: 0.19, ROC AUC: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "modelName = 'NaiveBayes'\n",
    "\n",
    "acuracias = []\n",
    "precisoes = []\n",
    "recalls = []\n",
    "f1_scores = []\n",
    "roc_auc_scores = []\n",
    "gmean_scores = []\n",
    "mcc_scores = []\n",
    "cohen_scores = []\n",
    "\n",
    "\n",
    "for j in tqdm(range(30)):\n",
    "    # Criando o diretorio\n",
    "    model_dir = os.path.join(\"Bagging2\", modelName)\n",
    "    model_dir = os.path.join(model_dir, str(j))\n",
    "\n",
    "    # Split the data\n",
    "    x_train, x_test, y_train, y_test = train_test_split(\n",
    "        x, y, test_size=0.2, stratify=y, random_state=j\n",
    "    )\n",
    "\n",
    "    loaded_estimators = []\n",
    "    for i in range(100):\n",
    "        model_path = os.path.join(model_dir, f'model_{i+1}.joblib')\n",
    "        Bagging = joblib.load(model_path)\n",
    "        loaded_estimators.append(Bagging)\n",
    "\n",
    "    # 5. Fazer a previsão combinada\n",
    "    y_preds = np.array([estimator.predict(x_test) for estimator in loaded_estimators])\n",
    "    previsoes = np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=0, arr=y_preds)\n",
    "\n",
    "    # Avaliar as métricas do modelo e armazenar na lista temporaria\n",
    "    cm = confusion_matrix(y_test, previsoes)\n",
    "    acuracia = accuracy_score(y_test, previsoes)\n",
    "    precisao = precision_score(y_test, previsoes)\n",
    "    recall = recall_score(y_test, previsoes)\n",
    "    f1 = f1_score(y_test, previsoes)\n",
    "    roc_auc = roc_auc_score(y_test, previsoes)\n",
    "    geoMedia = geometric_mean_score(y_test, previsoes)\n",
    "    mcc = matthews_corrcoef(y_test, previsoes)\n",
    "    kappa = cohen_kappa_score(y_test, previsoes)\n",
    "\n",
    "    \n",
    "    acuracias.append(acuracia)\n",
    "    precisoes.append(precisao)\n",
    "    recalls.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "    roc_auc_scores.append(roc_auc)\n",
    "    gmean_scores.append(geoMedia)\n",
    "    mcc_scores.append(mcc)\n",
    "    cohen_scores.append(kappa)\n",
    "\n",
    "    print(f'Repetição {i+1} {modelName} - Acurácia: {acuracia:.2f}, Precisão: {precisao:.2f}, Recall: {recall:.2f}, F1-score: {f1:.2f}, ROC AUC: {roc_auc:.2f}')\n",
    "\n",
    "# Criar um DataFrame com as métricas\n",
    "    metrics_df = pd.DataFrame({\n",
    "        'Accuracy': [np.mean(acuracias)],\n",
    "        'Precision': [np.mean(precisoes)],\n",
    "        'Recall': [np.mean(recalls)],\n",
    "        'F1_score': [np.mean(f1_scores)],\n",
    "        'Roc_auc': [np.mean(roc_auc_scores)],\n",
    "        'G-Mean': [np.mean(gmean_scores)],\n",
    "        'MCC': [np.mean(mcc_scores)],\n",
    "        'Cohen_Kappa': [np.mean(cohen_scores)],\n",
    "        'Accuracy_std': [np.std(acuracias)],\n",
    "        'Precision_std': [np.std(precisoes)],\n",
    "        'Recall_std': [np.std(recalls)],\n",
    "        'F1_score_std': [np.std(f1_scores)],\n",
    "        'Roc_auc_std': [np.std(roc_auc_scores)],\n",
    "        'G-Mean_std': [np.std(gmean_scores)],\n",
    "        'MCC_std': [np.std(mcc_scores)],\n",
    "        'Cohen_Kappa_std': [np.std(cohen_scores)],\n",
    "    })\n",
    "\n",
    "# Define the directory and file path\n",
    "directory = \"Metrics\"\n",
    "csv_path = os.path.join(directory, f'bagging{modelName}-2_metrics.csv')\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "metrics_df.to_csv(csv_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
