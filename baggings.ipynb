{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\josev\\anaconda3\\Lib\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "import sys\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import BernoulliNB, GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from tabulate import tabulate\n",
    "from tqdm import tqdm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.metrics import geometric_mean_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import matthews_corrcoef, cohen_kappa_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "import sys\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import BernoulliNB, GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from tabulate import tabulate\n",
    "from tqdm import tqdm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from deslib.dcs import OLA\n",
    "# from deslib.dcs import KNORA_U, KNORA_E\n",
    "from deslib.des import  KNOP, METADES\n",
    "from deslib.static import SingleBest, StackedClassifier\n",
    "from deslib.static import StaticSelection\n",
    "from imblearn.metrics import geometric_mean_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.load(r\"C:\\Users\\josev\\Desktop\\ProjetoPessoalNN\\GeorgeDarminton/x_all.npy\")\n",
    "y = np.load(r\"C:\\Users\\josev\\Desktop\\ProjetoPessoalNN\\GeorgeDarminton/y_all.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(103210, 8) (103210,)\n",
      "(25803, 8) (25803,)\n"
     ]
    }
   ],
   "source": [
    "x_all = np.load(r\"C:\\Users\\josev\\Desktop\\ProjetoPessoalNN\\GeorgeDarminton/x_all.npy\")\n",
    "y_all = np.load(r\"C:\\Users\\josev\\Desktop\\ProjetoPessoalNN\\GeorgeDarminton/y_all.npy\")\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_all, y_all, test_size=0.2, stratify=y_all, random_state=42)\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "baggings = {\n",
    "    # 'DT': DecisionTreeClassifier(criterion='gini'),\n",
    "    # 'NB': GaussianNB(),\n",
    "    'Knn': KNeighborsClassifier(n_neighbors=7),\n",
    "    'MLP': MLPClassifier(hidden_layer_sizes=(100), max_iter=1000)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:13<00:00,  2.17it/s]\n",
      "100%|██████████| 30/30 [00:13<00:00,  2.18it/s]\n",
      "100%|██████████| 30/30 [00:14<00:00,  2.09it/s]\n",
      "100%|██████████| 30/30 [00:14<00:00,  2.07it/s]\n",
      "100%|██████████| 30/30 [00:14<00:00,  2.10it/s]\n",
      "100%|██████████| 30/30 [00:13<00:00,  2.19it/s]\n",
      "100%|██████████| 30/30 [00:13<00:00,  2.15it/s]\n",
      "100%|██████████| 30/30 [00:14<00:00,  2.14it/s]\n",
      "100%|██████████| 30/30 [00:13<00:00,  2.18it/s]\n",
      "100%|██████████| 30/30 [00:13<00:00,  2.14it/s]\n",
      "100%|██████████| 30/30 [00:13<00:00,  2.18it/s]\n",
      "100%|██████████| 30/30 [00:13<00:00,  2.19it/s]\n",
      "100%|██████████| 30/30 [00:13<00:00,  2.22it/s]\n",
      "100%|██████████| 30/30 [00:13<00:00,  2.14it/s]\n",
      "100%|██████████| 30/30 [00:13<00:00,  2.15it/s]\n",
      "100%|██████████| 30/30 [00:13<00:00,  2.21it/s]\n",
      "100%|██████████| 30/30 [00:13<00:00,  2.24it/s]\n",
      "100%|██████████| 30/30 [00:13<00:00,  2.17it/s]\n",
      "100%|██████████| 30/30 [00:13<00:00,  2.14it/s]\n",
      "100%|██████████| 30/30 [00:13<00:00,  2.17it/s]\n",
      "100%|██████████| 30/30 [00:13<00:00,  2.21it/s]\n",
      "100%|██████████| 30/30 [00:13<00:00,  2.18it/s]\n",
      "100%|██████████| 30/30 [00:13<00:00,  2.20it/s]\n",
      "100%|██████████| 30/30 [00:13<00:00,  2.19it/s]\n",
      "100%|██████████| 30/30 [00:13<00:00,  2.23it/s]\n",
      "100%|██████████| 30/30 [00:13<00:00,  2.22it/s]\n",
      "100%|██████████| 30/30 [00:13<00:00,  2.22it/s]\n",
      "100%|██████████| 30/30 [00:13<00:00,  2.19it/s]\n",
      "100%|██████████| 30/30 [00:13<00:00,  2.16it/s]\n",
      "100%|██████████| 30/30 [00:13<00:00,  2.19it/s]\n",
      "100%|██████████| 30/30 [06:54<00:00, 13.80s/it]\n",
      "100%|██████████| 30/30 [59:41<00:00, 119.39s/it]\n",
      "100%|██████████| 30/30 [58:51<00:00, 117.72s/it]it]\n",
      "100%|██████████| 30/30 [58:23<00:00, 116.77s/it]s/it]\n",
      " 10%|█         | 3/30 [2:56:56<26:28:23, 3529.75s/it]"
     ]
    }
   ],
   "source": [
    "for modelName, model in baggings.items():\n",
    "    for i in tqdm(range(30)):\n",
    "    # Criando o diretorio\n",
    "        model_dir = os.path.join(\"E:/DrebinStudy/Balanced/Bagging2\", modelName)\n",
    "        model_dir = os.path.join(model_dir, str(i+1))\n",
    "        os.makedirs(model_dir, exist_ok=True)  # Create the directory if it doesn't exist\n",
    "\n",
    "        for j in tqdm(range(30)):\n",
    "\n",
    "            # print(\"entrou aqui\")\n",
    "            # Gerar uma amostra bootstrap\n",
    "            x_resampled, y_resampled = resample(x_train, y_train, replace=True)\n",
    "\n",
    "            # Balancear a amostra usando SMOTE\n",
    "            smote = SMOTE(sampling_strategy='auto', k_neighbors=5)\n",
    "            x_balanced, y_balanced = smote.fit_resample(x_resampled, y_resampled)\n",
    "\n",
    "\n",
    "            # Treinar o modelo na amostra balanceada\n",
    "            model.fit(x_balanced, y_balanced)\n",
    "            \n",
    "            # Salva o modelo treinado\n",
    "            model_path = os.path.join(model_dir, f'model_{j+1}.joblib')\n",
    "            joblib.dump(model, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acuracias = []\n",
    "precisoes = []\n",
    "recalls = []\n",
    "f1_scores = []\n",
    "roc_auc_scores = []\n",
    "gmean_scores = []\n",
    "mcc_scores = []\n",
    "cohen_scores = []\n",
    "\n",
    "\n",
    "for j in tqdm(range(30)):\n",
    "    # Criando o diretorio\n",
    "    model_dir = os.path.join(\"E:/DrebinStudy/Balanced/Bagging2\", modelName)\n",
    "    model_dir = os.path.join(model_dir, str(j+1))\n",
    "\n",
    "    loaded_estimators = []\n",
    "    for i in range(30):\n",
    "        model_path = os.path.join(model_dir, f'model_{i+1}.joblib')\n",
    "        Bagging = joblib.load(model_path)\n",
    "        loaded_estimators.append(Bagging)\n",
    "\n",
    "    # 5. Fazer a previsão combinada\n",
    "    y_preds = np.array([estimator.predict(x_test) for estimator in loaded_estimators])\n",
    "    previsoes = np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=0, arr=y_preds)\n",
    "\n",
    "    # Avaliar as métricas do modelo e armazenar na lista temporaria\n",
    "    cm = confusion_matrix(y_test, previsoes)\n",
    "    acuracia = accuracy_score(y_test, previsoes)\n",
    "    precisao = precision_score(y_test, previsoes)\n",
    "    recall = recall_score(y_test, previsoes)\n",
    "    f1 = f1_score(y_test, previsoes)\n",
    "    roc_auc = roc_auc_score(y_test, previsoes)\n",
    "    geoMedia = geometric_mean_score(y_test, previsoes)\n",
    "    mcc = matthews_corrcoef(y_test, previsoes)\n",
    "    kappa = cohen_kappa_score(y_test, previsoes)\n",
    "\n",
    "    \n",
    "    acuracias.append(acuracia)\n",
    "    precisoes.append(precisao)\n",
    "    recalls.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "    roc_auc_scores.append(roc_auc)\n",
    "    gmean_scores.append(geoMedia)\n",
    "    mcc_scores.append(mcc)\n",
    "    cohen_scores.append(kappa)\n",
    "\n",
    "    print(f'Repetição {i+1} {modelName} - Acurácia: {acuracia:.2f}, Precisão: {precisao:.2f}, Recall: {recall:.2f}, F1-score: {f1:.2f}, ROC AUC: {roc_auc:.2f}')\n",
    "\n",
    "# Criar um DataFrame com as métricas\n",
    "    metrics_df = pd.DataFrame({\n",
    "        'Accuracy': [np.mean(acuracias)],\n",
    "        'Precision': [np.mean(precisoes)],\n",
    "        'Recall': [np.mean(recalls)],\n",
    "        'F1_score': [np.mean(f1_scores)],\n",
    "        'Roc_auc': [np.mean(roc_auc_scores)],\n",
    "        'G-Mean': [np.mean(gmean_scores)],\n",
    "        'MCC': [np.mean(mcc_scores)],\n",
    "        'Cohen_Kappa': [np.mean(cohen_scores)],\n",
    "        'Accuracy_std': [np.std(acuracias)],\n",
    "        'Precision_std': [np.std(precisoes)],\n",
    "        'Recall_std': [np.std(recalls)],\n",
    "        'F1_score_std': [np.std(f1_scores)],\n",
    "        'Roc_auc_std': [np.std(roc_auc_scores)],\n",
    "        'G-Mean_std': [np.std(gmean_scores)],\n",
    "        'MCC_std': [np.std(mcc_scores)],\n",
    "        'Cohen_Kappa_std': [np.std(cohen_scores)],\n",
    "    })\n",
    "\n",
    "csv_path = os.path.join(\"E:/DrebinStudy/Balanced/Metrics\", f'bagging{modelName}-2_metrics.csv')\n",
    "metrics_df.to_csv(csv_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
